{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV-qaRjjh51v"
   },
   "source": [
    "# Hybrid Recommendation System\n",
    "\n",
    "**Team Structure:**\n",
    "- Member 1: Infrastructure, Data Loading, Fusion & Evaluation\n",
    "- Member 2: Collaborative Filtering (ALS)\n",
    "- Member 3: Content-Based Filtering (TF-IDF + LSH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z3aeJVqkPIa"
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnzLbX57kUnJ"
   },
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GMg3a2fqh51y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from math import log2\n",
    "\n",
    "# Fix for Windows\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType, FloatType, StructType, StructField"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d--B_svch51z"
   },
   "source": [
    "### 1.2 Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7xDJxcgHh511"
   },
   "outputs": [],
   "source": [
    "DATA_URL = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
    "DATA_DIR = \"data\"\n",
    "DATASET_DIR = os.path.join(DATA_DIR, \"ml-1m\")\n",
    "ZIP_PATH = os.path.join(DATA_DIR, \"ml-1m.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2xaxdp_xh512"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t3cKFv2Bh513"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DATASET_DIR):\n",
    "\n",
    "    if not os.path.exists(ZIP_PATH):\n",
    "        print(\"Downloading MovieLens ml-1m...\")\n",
    "        urllib.request.urlretrieve(DATA_URL, ZIP_PATH)\n",
    "\n",
    "    print(\"Extracting...\")\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew2EJ0KCh513"
   },
   "source": [
    "### 1.3 Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zH6tSX_bh513"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"MMDS\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"20\") \\\n",
    "    .config(\"spark.default.parallelism\", \"20\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"400m\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y95TFnL2h514"
   },
   "source": [
    "### 1.4 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBLTLe1th514",
    "outputId": "fc2b2efd-dfe3-4498-e34a-ba1de16a3140"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = spark.read.text(os.path.join(DATASET_DIR, \"users.dat\")).select(\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(0).cast(IntegerType()).alias(\"user_id\"),\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(1).alias(\"gender\"),\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(2).cast(IntegerType()).alias(\"age\"),\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(3).cast(IntegerType()).alias(\"occupation\"),\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(4).alias(\"zip_code\")\n",
    ")\n",
    "users_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFLr1EX2h514",
    "outputId": "08e9e755-c1b5-4160-d625-643f128fc28e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df = spark.read.text(os.path.join(DATASET_DIR, \"movies.dat\")).select(\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(0).cast(IntegerType()).alias(\"item_id\"),\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(1).alias(\"title\"),\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(2).alias(\"genres\")\n",
    ")\n",
    "items_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uafyQhs3h515",
    "outputId": "1af79a1e-18be-442c-d72f-fa38cf29fbed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = spark.read.text(os.path.join(DATASET_DIR, \"ratings.dat\")).select(\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(0).cast(IntegerType()).alias(\"user_id\"),\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(1).cast(IntegerType()).alias(\"item_id\"),\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(2).cast(FloatType()).alias(\"rating\"),\n",
    "    F.split(F.col(\"value\"), \"::\").getItem(3).cast(IntegerType()).alias(\"timestamp\")\n",
    ")\n",
    "ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36xJVL9Ih515",
    "outputId": "30aaf041-8590-4453-c239-224def2157c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+----------+--------+\n",
      "|user_id|gender|age|occupation|zip_code|\n",
      "+-------+------+---+----------+--------+\n",
      "|      1|     F|  1|        10|   48067|\n",
      "|      2|     M| 56|        16|   70072|\n",
      "|      3|     M| 25|        15|   55117|\n",
      "|      4|     M| 45|         7|   02460|\n",
      "|      5|     M| 25|        20|   55455|\n",
      "+-------+------+---+----------+--------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "users_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtXD-ucvh515",
    "outputId": "fe9aaea5-5745-46bc-aa52-f8438ba62fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|item_id|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Animation|Childre...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|        Comedy|Drama|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "items_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BI5_IghMh515",
    "outputId": "e390641c-b757-445d-af40-8b20d25ed3a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+\n",
      "|user_id|item_id|rating|timestamp|\n",
      "+-------+-------+------+---------+\n",
      "|      1|   1193|   5.0|978300760|\n",
      "|      1|    661|   3.0|978302109|\n",
      "|      1|    914|   3.0|978301968|\n",
      "|      1|   3408|   4.0|978300275|\n",
      "|      1|   2355|   5.0|978824291|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYsOYCQEh515"
   },
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmGEbwy3mDDY"
   },
   "source": [
    "### 2.1 Rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cARZQAvGh515",
    "outputId": "aa9e00a1-9cec-4884-c3e8-bce725927b73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users:            6,040\n",
      "Movies:           3,883\n",
      "Ratings:          1,000,209\n",
      "Sparsity:         95.74%\n",
      "Avg ratings/user: 165.6\n",
      "Avg ratings/movie:257.6\n"
     ]
    }
   ],
   "source": [
    "num_users = users_df.count()\n",
    "num_items = items_df.count()\n",
    "num_ratings = ratings_df.count()\n",
    "sparsity = (1 - (num_ratings / (num_users * num_items))) * 100\n",
    "\n",
    "print(f\"Users:            {num_users:,}\")\n",
    "print(f\"Movies:           {num_items:,}\")\n",
    "print(f\"Ratings:          {num_ratings:,}\")\n",
    "print(f\"Sparsity:         {sparsity:.2f}%\")\n",
    "print(f\"Avg ratings/user: {num_ratings/num_users:.1f}\")\n",
    "print(f\"Avg ratings/movie:{num_ratings/num_items:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQaH_GJVmLpj"
   },
   "source": [
    "### 2.2 Rating distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlDMVOJNh515",
    "outputId": "dd79f2eb-46dd-4966-cbbc-0daebd89857e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|rating| count|\n",
      "+------+------+\n",
      "|   1.0| 56174|\n",
      "|   2.0|107557|\n",
      "|   3.0|261197|\n",
      "|   4.0|348971|\n",
      "|   5.0|226310|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.groupBy(\"rating\").count().orderBy(\"rating\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMl6TOXvmQiN"
   },
   "source": [
    "### 2.3 Genre distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uolq8hkh515",
    "outputId": "8a63ec2b-7dc1-4c5a-9a12-390dbc0b070c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|      genre|count|\n",
      "+-----------+-----+\n",
      "|      Drama| 1603|\n",
      "|     Comedy| 1200|\n",
      "|     Action|  503|\n",
      "|   Thriller|  492|\n",
      "|    Romance|  471|\n",
      "|     Horror|  343|\n",
      "|  Adventure|  283|\n",
      "|     Sci-Fi|  276|\n",
      "| Children's|  251|\n",
      "|      Crime|  211|\n",
      "|        War|  143|\n",
      "|Documentary|  127|\n",
      "|    Musical|  114|\n",
      "|    Mystery|  106|\n",
      "|  Animation|  105|\n",
      "|    Western|   68|\n",
      "|    Fantasy|   68|\n",
      "|  Film-Noir|   44|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items_df.select(F.explode(F.split(F.col(\"genres\"), \"\\\\|\")).alias(\"genre\")) \\\n",
    "    .groupBy(\"genre\").count().orderBy(F.desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M4BhkBOmoPr"
   },
   "source": [
    "### 2.4 User gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWtkOG1rh515",
    "outputId": "1955049f-0ef8-40c7-8568-765dfc3d126c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|     F| 1709|\n",
      "|     M| 4331|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.groupBy(\"gender\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_t-YXlxmtrw"
   },
   "source": [
    "### 2.5 User age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tt5JfAqKh515",
    "outputId": "5e18a191-b997-4b90-fcb5-9576ecaafb17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "|  1|  222|\n",
      "| 18| 1103|\n",
      "| 25| 2096|\n",
      "| 35| 1193|\n",
      "| 45|  550|\n",
      "| 50|  496|\n",
      "| 56|  380|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.groupBy(\"age\").count().orderBy(\"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWmkYV91h516"
   },
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "r2lL2tL-h516"
   },
   "outputs": [],
   "source": [
    "def chronological_split(ratings_df, train_ratio=0.8, min_train_ratings=5):\n",
    "    user_time_window = Window.partitionBy(\"user_id\").orderBy(\"timestamp\")\n",
    "    user_count_window = Window.partitionBy(\"user_id\")\n",
    "\n",
    "    ratings_with_rank = ratings_df.withColumn(\n",
    "        \"row_num\", F.row_number().over(user_time_window)\n",
    "    ).withColumn(\n",
    "        \"user_total\", F.count(\"*\").over(user_count_window)\n",
    "    ).withColumn(\n",
    "        \"train_threshold\", F.floor(F.col(\"user_total\") * train_ratio)\n",
    "    )\n",
    "\n",
    "    ratings_valid = ratings_with_rank.filter(\n",
    "        F.col(\"train_threshold\") >= min_train_ratings\n",
    "    )\n",
    "\n",
    "    ratings_labeled = ratings_valid.withColumn(\n",
    "        \"split\",\n",
    "        F.when(F.col(\"row_num\") <= F.col(\"train_threshold\"), \"train\").otherwise(\"test\")\n",
    "    )\n",
    "\n",
    "    original_columns = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "    train_df = ratings_labeled.filter(F.col(\"split\") == \"train\").select(original_columns)\n",
    "    test_df = ratings_labeled.filter(F.col(\"split\") == \"test\").select(original_columns)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7bz6lAKh516",
    "outputId": "43cfc1af-6a46-4cdf-f794-ca94e38ad55a"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = chronological_split(ratings_df, train_ratio=0.8, min_train_ratings=5)\n",
    "train_df = train_df.cache()\n",
    "test_df = test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ambqvc_Fh516",
    "outputId": "a85471a3-77c0-4640-d912-043c97d3bca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 797,758 ratings\n",
      "Test: 202,451 ratings\n",
      "Users in train: 6,040\n",
      "Users in test: 6,040\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {train_df.count():,} ratings\")\n",
    "print(f\"Test: {test_df.count():,} ratings\")\n",
    "print(f\"Users in train: {train_df.select('user_id').distinct().count():,}\")\n",
    "print(f\"Users in test: {test_df.select('user_id').distinct().count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZBXPcymh517"
   },
   "source": [
    "## 4. Collaborative Filtering (ALS)\n",
    "\n",
    "Implement using `pyspark.ml.recommendation.ALS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tR9qfStQh517"
   },
   "outputs": [],
   "source": [
    "class CollaborativeFilter:\n",
    "\n",
    "    def __init__(self, rank=10, regParam=0.1, maxIter=10):\n",
    "        self.als = ALS(\n",
    "            userCol=\"user_id\",\n",
    "            itemCol=\"item_id\",\n",
    "            ratingCol=\"rating\",\n",
    "            rank=rank,\n",
    "            regParam=regParam,\n",
    "            maxIter=maxIter,\n",
    "            coldStartStrategy=\"drop\",\n",
    "            nonnegative=True\n",
    "        )\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, df):\n",
    "        self.model = self.als.fit(df)\n",
    "\n",
    "    def get_recommendations(self, df, k=10):\n",
    "        \"\"\"Get top-K recommendations\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Call train() first.\")\n",
    "\n",
    "        users = df.select(\"user_id\").distinct()\n",
    "        user_recs = self.model.recommendForUserSubset(users, k)\n",
    "\n",
    "        return user_recs.select(\n",
    "            F.col(\"user_id\"),\n",
    "            F.explode(\"recommendations\").alias(\"rec\")\n",
    "        ).select(\n",
    "            F.col(\"user_id\"),\n",
    "            F.col(\"rec.item_id\").cast(IntegerType()).alias(\"item_id\"),\n",
    "            F.col(\"rec.rating\").alias(\"prediction\")\n",
    "        )\n",
    "\n",
    "    def predict(self, df):\n",
    "        \"\"\"Predict ratings for user-item pairs in test\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Train should be called first\")\n",
    "        return self.model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FxOIEA61GHB5"
   },
   "outputs": [],
   "source": [
    "cf = CollaborativeFilter(rank=10, regParam=0.1, maxIter=10)\n",
    "cf.train(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tnm-lWUrGgMU"
   },
   "outputs": [],
   "source": [
    "als_recs = cf.get_recommendations(test_df, k=100).withColumnRenamed(\"prediction\", \"als_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzSY2W66h517",
    "outputId": "b0348579-c8ab-443b-f6b3-6f9492bb92c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+\n",
      "|user_id|item_id|als_score|\n",
      "+-------+-------+---------+\n",
      "|     95|   3905| 4.470003|\n",
      "|     95|   1851| 4.413235|\n",
      "|     95|   3092|4.3593006|\n",
      "|     95|   2905| 4.310626|\n",
      "|     95|    318|4.2543035|\n",
      "|     95|    260|4.2513843|\n",
      "|     95|   1198|4.2234735|\n",
      "|     95|    527|4.1753764|\n",
      "|     95|   2931|4.1601114|\n",
      "|     95|     50| 4.154743|\n",
      "+-------+-------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "als_recs.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxfposUDh517"
   },
   "source": [
    "### Bonus: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bmVnX8K7h517"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMWQPlANh517"
   },
   "source": [
    "## 5. Content-Based Filtering (TF-IDF + LSH)\n",
    "\n",
    "Implement using `pyspark.ml.feature` (Tokenizer, HashingTF, IDF, BucketedRandomProjectionLSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building content features (tfidf + bigrams)\n",
      "checked 3883 movies\n",
      "indexing with minhash LSH\n",
      "cmputing similarity graph\n",
      "indexed 988212 similar item pairs\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, NGram, MinHashLSH\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import (\n",
    "    col, split, concat_ws, regexp_extract, udf, array_intersect, \n",
    "    size, sum as _sum, desc, row_number\n",
    ")\n",
    "\n",
    "class ContentBasedFilter:\n",
    "    def __init__(self, num_features=5000, bigram_features=3000, num_hash_tables=10):\n",
    "        self.num_features = num_features\n",
    "        self.bigram_features = bigram_features\n",
    "        self.num_hash_tables = num_hash_tables\n",
    "        self.jaccard_threshold = 0.1\n",
    "        self.genre_weight = 4\n",
    "        self.min_genre_overlap = 1\n",
    "        \n",
    "\n",
    "        self.lsh_model = None\n",
    "        self.vector_model = None\n",
    "        self.movies_binary = None\n",
    "        self.similar_pairs = None\n",
    "\n",
    "    def combine_binarize_udf(self):\n",
    "        def process_vectors(v1, v2):\n",
    "            if v1 is None: \n",
    "                return None\n",
    "            indices = [int(i) for i in v1.indices]\n",
    "            \n",
    "            if v2 is not None:\n",
    "                offset = int(v1.size)\n",
    "                indices += [int(i) + offset for i in v2.indices]\n",
    "                total_size = offset + int(v2.size)\n",
    "            else:\n",
    "                total_size = int(v1.size)\n",
    "            \n",
    "            values = [1.0] * len(indices)\n",
    "            return Vectors.sparse(total_size, sorted(indices), values)\n",
    "            \n",
    "        return udf(process_vectors, VectorUDT())\n",
    "\n",
    "    def train_features(self, items_df):\n",
    "        print(\"building content features (tfidf + bigrams)\")\n",
    "        \n",
    "        df = (\n",
    "            items_df\n",
    "            .withColumn(\"year\", regexp_extract(col(\"title\"), r\"\\((\\d{4})\\)\", 1))\n",
    "            .withColumn(\"decade\", regexp_extract(col(\"title\"), r\"\\((\\d{3})\\d\\)\", 1))\n",
    "            .withColumn(\"genres_spaced\", F.regexp_replace(col(\"genres\"), r\"\\|\", \" \"))\n",
    "            .withColumn(\"content\", concat_ws(\n",
    "                \" \", \n",
    "                col(\"title\"),\n",
    "                col(\"genres_spaced\"), col(\"genres_spaced\"), col(\"genres_spaced\"), col(\"genres_spaced\"),\n",
    "                col(\"year\"), col(\"decade\")\n",
    "            ))\n",
    "        )\n",
    "\n",
    "        stages = []\n",
    "\n",
    "        stages += [\n",
    "            Tokenizer(inputCol=\"content\", outputCol=\"raw_words\"),\n",
    "            StopWordsRemover(inputCol=\"raw_words\", outputCol=\"words\")\n",
    "        ]\n",
    "        \n",
    "        stages += [\n",
    "            HashingTF(inputCol=\"words\", outputCol=\"tf_uni\", numFeatures=self.num_features),\n",
    "            IDF(inputCol=\"tf_uni\", outputCol=\"tfidf_uni\", minDocFreq=1)\n",
    "        ]\n",
    "        \n",
    "        stages += [\n",
    "            NGram(n=2, inputCol=\"words\", outputCol=\"bigrams\"),\n",
    "            HashingTF(inputCol=\"bigrams\", outputCol=\"tf_bi\", numFeatures=self.bigram_features),\n",
    "            IDF(inputCol=\"tf_bi\", outputCol=\"tfidf_bi\", minDocFreq=1)\n",
    "        ]\n",
    "        \n",
    "        pipeline = Pipeline(stages=stages)\n",
    "        self.vector_model = pipeline.fit(df)\n",
    "        features_df = self.vector_model.transform(df)\n",
    "        \n",
    "        combiner = self.combine_binarize_udf()\n",
    "        self.movies_binary = (\n",
    "            features_df\n",
    "            .withColumn(\"binary_features\", combiner(\"tfidf_uni\", \"tfidf_bi\"))\n",
    "            .select(\"item_id\", \"title\", \"genres\", \"binary_features\")\n",
    "            .cache()\n",
    "        )\n",
    "        \n",
    "        print(f\"checked {self.movies_binary.count()} movies\")\n",
    "\n",
    "    def build_lsh_index(self):\n",
    "        print(\"indexing with minhash LSH\")\n",
    "        \n",
    "        mh = MinHashLSH(\n",
    "            inputCol=\"binary_features\", \n",
    "            outputCol=\"hashes\", \n",
    "            numHashTables=self.num_hash_tables,\n",
    "            seed=42\n",
    "        )\n",
    "        self.lsh_model = mh.fit(self.movies_binary)\n",
    "        \n",
    "        dist_threshold = 1.0 - self.jaccard_threshold\n",
    "        \n",
    "        print(f\"cmputing similarity graph\")\n",
    "        raw_pairs = self.lsh_model.approxSimilarityJoin(\n",
    "            self.movies_binary, self.movies_binary, \n",
    "            threshold=dist_threshold, \n",
    "            distCol=\"jaccard_dist\"\n",
    "        )\n",
    "        \n",
    "        pairs = raw_pairs.select(\n",
    "            col(\"datasetA.item_id\").alias(\"item_a\"),\n",
    "            col(\"datasetB.item_id\").alias(\"item_b\"),\n",
    "            (1.0 - col(\"jaccard_dist\")).alias(\"similarity\")\n",
    "        ).filter(\"item_a != item_b\")\n",
    "        \n",
    "        self.similar_pairs = pairs.cache()\n",
    "        print(f\"indexed {self.similar_pairs.count()} similar item pairs\")\n",
    "\n",
    "    def recommend_for_users(self, train_df, items_df, k=10):\n",
    "        print(\"generating content-based recommendations\")\n",
    "        \n",
    "        user_history = train_df.filter(col(\"rating\") >= 4.0).select(\n",
    "            col(\"user_id\"), col(\"item_id\").alias(\"seed_item\"), col(\"rating\")\n",
    "        )\n",
    "\n",
    "        candidates = user_history.join(\n",
    "            self.similar_pairs,\n",
    "            user_history.seed_item == self.similar_pairs.item_a\n",
    "        )\n",
    "        \n",
    "        genre_df = items_df.select(\"item_id\", split(col(\"genres\"), r\"\\|\").alias(\"genres_arr\"))        \n",
    "        \n",
    "        candidates_enriched = (\n",
    "            candidates.alias(\"c\")\n",
    "            .join(\n",
    "                genre_df.alias(\"seed_g\"), \n",
    "                col(\"c.seed_item\") == col(\"seed_g.item_id\")\n",
    "            )\n",
    "            .join(\n",
    "                genre_df.alias(\"cand_g\"), \n",
    "                col(\"c.item_b\") == col(\"cand_g.item_id\")\n",
    "            )\n",
    "            .select(\n",
    "                \"c.user_id\", \n",
    "                col(\"c.item_b\").alias(\"candidate_item\"),\n",
    "                \"c.rating\", \n",
    "                \"c.similarity\",\n",
    "                size(array_intersect(\n",
    "                    col(\"seed_g.genres_arr\"), \n",
    "                    col(\"cand_g.genres_arr\")\n",
    "                )).alias(\"genre_overlap\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        filtered = candidates_enriched.filter(col(\"genre_overlap\") >= self.min_genre_overlap)\n",
    "\n",
    "        scored = filtered.withColumn(\n",
    "            \"score\", \n",
    "            col(\"rating\") * col(\"similarity\") * (1.0 + 0.25 * col(\"genre_overlap\"))\n",
    "        )\n",
    "\n",
    "        recs = scored.groupBy(\"user_id\", \"candidate_item\").agg(_sum(\"score\").alias(\"content_score\"))\n",
    "        \n",
    "        seen_items = train_df.select(\"user_id\", \"item_id\").distinct().alias(\"seen\")\n",
    "        recs_alias = recs.alias(\"recs\")\n",
    "        \n",
    "        final_recs = recs_alias.join(\n",
    "            seen_items,\n",
    "            (col(\"recs.user_id\") == col(\"seen.user_id\")) & \n",
    "            (col(\"recs.candidate_item\") == col(\"seen.item_id\")),\n",
    "            \"left_anti\"\n",
    "        ).select(\n",
    "            col(\"recs.user_id\"), \n",
    "            col(\"recs.candidate_item\").alias(\"item_id\"), \n",
    "            col(\"recs.content_score\")\n",
    "        )\n",
    "\n",
    "        window = Window.partitionBy(\"user_id\").orderBy(desc(\"content_score\"))\n",
    "        return (\n",
    "            final_recs\n",
    "            .withColumn(\"rank\", row_number().over(window))\n",
    "            .filter(col(\"rank\") <= k)\n",
    "            .drop(\"rank\")\n",
    "        )\n",
    "\n",
    "cb_filter = ContentBasedFilter()\n",
    "cb_filter.train_features(items_df)\n",
    "cb_filter.build_lsh_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating content-based recommendations\n"
     ]
    }
   ],
   "source": [
    "content_recs = cb_filter.recommend_for_users(train_df, items_df, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+\n",
      "|user_id|item_id|     content_score|\n",
      "+-------+-------+------------------+\n",
      "|     95|   1744| 22.83967523704366|\n",
      "|     95|   1591|22.473956043956044|\n",
      "|     95|    849|21.873400389932648|\n",
      "|     95|   2334|21.532246786394385|\n",
      "|     95|   2058| 21.53224678639438|\n",
      "+-------+-------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "content_recs = content_recs.cache()\n",
    "content_recs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUJnnDrCh518"
   },
   "source": [
    "## 6.Fusion & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9PM6sSWqh518"
   },
   "outputs": [],
   "source": [
    "ALPHA = 0.7\n",
    "K = 10\n",
    "RELEVANCE_THRESHOLD = 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-PgBqkXh518"
   },
   "source": [
    "### 6.1 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "z3B5QAFnh518"
   },
   "outputs": [],
   "source": [
    "def normalize(df, col_name):\n",
    "    stats = df.agg(F.min(col_name).alias(\"min\"), F.max(col_name).alias(\"max\")).collect()[0]\n",
    "    if stats[\"max\"] == stats[\"min\"]:\n",
    "        return df.withColumn(col_name + \"_norm\", F.lit(0.5))\n",
    "    return df.withColumn(col_name + \"_norm\", (F.col(col_name) - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHZure3Wh518"
   },
   "source": [
    "### 6.2 Hybrid Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "63j6mXT6h518"
   },
   "outputs": [],
   "source": [
    "als_norm = normalize(als_recs, \"als_score\")\n",
    "content_norm = normalize(content_recs, \"content_score\")\n",
    "\n",
    "hybrid_recs = als_norm.select(\"user_id\", \"item_id\", \"als_score_norm\") \\\n",
    "    .join(content_norm.select(\"user_id\", \"item_id\", \"content_score_norm\"), [\"user_id\", \"item_id\"], \"full_outer\") \\\n",
    "    .fillna(0) \\\n",
    "    .withColumn(\"final_score\", ALPHA * F.col(\"als_score_norm\") + (1 - ALPHA) * F.col(\"content_score_norm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEQFjotih518",
    "outputId": "6edb4ce3-e385-4ee9-e167-5ea8474b4f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+------------------+------------------+\n",
      "|user_id|item_id|    als_score_norm|content_score_norm|       final_score|\n",
      "+-------+-------+------------------+------------------+------------------+\n",
      "|   2155|   2964|               1.0|               0.0|               0.7|\n",
      "|    283|   2964|0.9698151700844673|               0.0| 0.678870619059127|\n",
      "|   5258|   2964|0.9697667223390415|               0.0| 0.678836705637329|\n",
      "|     46|   2332|0.9629095211067962|               0.0|0.6740366647747573|\n",
      "|    356|   2964|0.9624401982957583|               0.0|0.6737081388070308|\n",
      "|   2867|   2964|0.9327210792037601|               0.0| 0.652904755442632|\n",
      "|   4751|   2197|0.9295460636668155|               0.0|0.6506822445667708|\n",
      "|     46|   1421|0.9260141680602427|               0.0|0.6482099176421698|\n",
      "|     46|   2964| 0.924343074189654|               0.0|0.6470401519327578|\n",
      "|   4751|   2823|0.9179485214437122|               0.0|0.6425639650105985|\n",
      "+-------+-------+------------------+------------------+------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "hybrid_recs.orderBy(F.desc(\"final_score\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+-------------------+------------------+\n",
      "|user_id|item_id|    als_score_norm| content_score_norm|       final_score|\n",
      "+-------+-------+------------------+-------------------+------------------+\n",
      "|   4277|     53|0.6619954703713671| 0.5904650803512171|0.6405363533653221|\n",
      "|   4169|     53|0.5907159593292562| 0.7100814164276092|0.6265255964587622|\n",
      "|   4169|   2197|0.5363586097405134| 0.7420784076418976|0.5980745491109287|\n",
      "|   4277|   2579|0.6177101479358188| 0.5430159889973913|0.5953019002542905|\n",
      "|   1835|     53| 0.648898089598216|0.39215405067471004|0.5718748779211642|\n",
      "|    187|   2197|0.6132271217938433|0.46941409482066127|0.5700832137018887|\n",
      "|   1448|     53|0.5899127632385575| 0.5233646290001704|0.5699483229670413|\n",
      "|    195|     53|0.6529252201000901| 0.3695371984674346|0.5679088136102934|\n",
      "|   1680|   3817|0.6208199121333001|0.41946522137832376|0.5604135049068072|\n",
      "|   5878|   2197| 0.675955173900218| 0.2770115983667207|0.5562721012401688|\n",
      "+-------+-------+------------------+-------------------+------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "hybrid_recs.orderBy(F.desc(\"final_score\")).filter((F.col(\"als_score_norm\") > 0.2) & (F.col(\"content_score_norm\") > 0.2)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "als pairs: 604000\n",
      "content pairs: 603761\n",
      "overlap: 10692\n"
     ]
    }
   ],
   "source": [
    "als_pairs = als_recs.select(\"user_id\", \"item_id\").distinct()\n",
    "content_pairs = content_recs.select(\"user_id\", \"item_id\").distinct()\n",
    "\n",
    "overlap = als_pairs.intersect(content_pairs).count()\n",
    "print(f\"als pairs: {als_pairs.count()}\")\n",
    "print(f\"content pairs: {content_pairs.count()}\")\n",
    "print(f\"overlap: {overlap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO0RqOEah518"
   },
   "source": [
    "### 6.3 Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-6zhUdyvh518"
   },
   "outputs": [],
   "source": [
    "ground_truth = test_df.filter(F.col(\"rating\") >= RELEVANCE_THRESHOLD) \\\n",
    "    .groupBy(\"user_id\").agg(F.collect_list(\"item_id\").alias(\"relevant_items\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LPsv7vPh518"
   },
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Qi9mYfoYh518"
   },
   "outputs": [],
   "source": [
    "def get_top_k(recs_df, score_col, k):\n",
    "    window = Window.partitionBy(\"user_id\").orderBy(F.desc(score_col))\n",
    "    ranked = recs_df.withColumn(\"rank\", F.row_number().over(window)) \\\n",
    "        .filter(F.col(\"rank\") <= k)\n",
    "\n",
    "    return ranked.groupBy(\"user_id\").agg(\n",
    "        F.array_sort(F.collect_list(F.struct(\"rank\", \"item_id\"))).alias(\"ranked_structs\")\n",
    "    ).withColumn(\n",
    "        \"recommended_items\",\n",
    "        F.expr(\"transform(ranked_structs, x -> x.item_id)\")\n",
    "    ).drop(\"ranked_structs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "eu_sXcNwh518"
   },
   "outputs": [],
   "source": [
    "def precision_at_k(top_k_df, ground_truth_df, k):\n",
    "    joined = top_k_df.join(ground_truth_df, \"user_id\")\n",
    "    result = joined.withColumn(\"hits\", F.size(F.array_intersect(\"recommended_items\", \"relevant_items\"))) \\\n",
    "        .agg(F.avg(F.col(\"hits\") / k)).collect()[0][0]\n",
    "    return result or 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "bMbB0jRrh519"
   },
   "outputs": [],
   "source": [
    "def recall_at_k(top_k_df, ground_truth_df):\n",
    "    joined = top_k_df.join(ground_truth_df, \"user_id\")\n",
    "    result = joined.withColumn(\"hits\", F.size(F.array_intersect(\"recommended_items\", \"relevant_items\"))) \\\n",
    "        .withColumn(\"recall\", F.when(F.size(\"relevant_items\") > 0, F.col(\"hits\") / F.size(\"relevant_items\")).otherwise(0)) \\\n",
    "        .agg(F.avg(\"recall\")).collect()[0][0]\n",
    "    return result or 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "LqilPysEh519"
   },
   "outputs": [],
   "source": [
    "def ndcg_at_k(top_k_df, ground_truth_df, k):\n",
    "    joined = top_k_df.join(ground_truth_df, \"user_id\")\n",
    "    exploded = joined.select(\n",
    "        \"user_id\",\n",
    "        \"relevant_items\",\n",
    "        F.posexplode(\"recommended_items\").alias(\"pos\", \"item_id\")\n",
    "    ).withColumn(\"item_id\", F.col(\"item_id\").cast(IntegerType()))\n",
    "\n",
    "    with_dcg = exploded \\\n",
    "        .withColumn(\"rel\", F.when(F.array_contains(\"relevant_items\", F.col(\"item_id\")), 1.0).otherwise(0.0)) \\\n",
    "        .withColumn(\"dcg\", F.col(\"rel\") / F.log2(F.col(\"pos\") + 2)) \\\n",
    "        .groupBy(\"user_id\", \"relevant_items\").agg(F.sum(\"dcg\").alias(\"dcg\"))\n",
    "\n",
    "    idcg_vals = [sum(1.0 / log2(i + 2) for i in range(n)) for n in range(k + 1)]\n",
    "    idcg_map = F.create_map(*[x for i, v in enumerate(idcg_vals) for x in (F.lit(i), F.lit(v))])\n",
    "\n",
    "    result = with_dcg \\\n",
    "        .withColumn(\"num_rel\", F.least(F.size(\"relevant_items\"), F.lit(k))) \\\n",
    "        .withColumn(\"idcg\", idcg_map[F.col(\"num_rel\")]) \\\n",
    "        .withColumn(\"ndcg\", F.when(F.col(\"idcg\") > 0, F.col(\"dcg\") / F.col(\"idcg\")).otherwise(0)) \\\n",
    "        .agg(F.avg(\"ndcg\")).collect()[0][0]\n",
    "    return result or 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Fb28KwU6h51_"
   },
   "outputs": [],
   "source": [
    "def evaluate(recs_df, score_col, name):\n",
    "    if recs_df.count() == 0:\n",
    "        print(f\"{name}: No recommendations (not implemented)\")\n",
    "        return {\"Precision@10\": 0.0, \"Recall@10\": 0.0, \"NDCG@10\": 0.0}\n",
    "\n",
    "    top_k = get_top_k(recs_df, score_col, K)\n",
    "    p = precision_at_k(top_k, ground_truth, K)\n",
    "    r = recall_at_k(top_k, ground_truth)\n",
    "    n = ndcg_at_k(top_k, ground_truth, K)\n",
    "\n",
    "    print(f\"{name}: P@{K}={p:.4f}, R@{K}={r:.4f}, NDCG@{K}={n:.4f}\")\n",
    "    return {\"Precision@10\": p, \"Recall@10\": r, \"NDCG@10\": n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcQId4lLh52C"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4_55bcPh52C",
    "outputId": "6b5486e9-a788-4a38-b856-37791abbc479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS: P@10=0.0099, R@10=0.0081, NDCG@10=0.0088\n"
     ]
    }
   ],
   "source": [
    "als_metrics = evaluate(als_recs, \"als_score\", \"ALS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "La8eg0aFh52D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Based: P@10=0.0149, R@10=0.0167, NDCG@10=0.0188\n"
     ]
    }
   ],
   "source": [
    "content_metrics = evaluate(content_recs, \"content_score\", \"Content-Based\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "9hpFNv0Vh52D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid: P@10=0.0108, R@10=0.0088, NDCG@10=0.0100\n"
     ]
    }
   ],
   "source": [
    "hybrid_metrics = evaluate(hybrid_recs, \"final_score\", \"Hybrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kL3phVEuh52D"
   },
   "source": [
    "### Bonus: GBT Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "eZfDCdK1h52D"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqAeFwu6h52D"
   },
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "FlHvgvrWh52D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------------+\n",
      "|        Model|        Precision@10|           Recall@10|             NDCG@10|\n",
      "+-------------+--------------------+--------------------+--------------------+\n",
      "|          ALS| 0.00989121338912142|0.008075643298256809|0.008834882243884373|\n",
      "|Content-Based| 0.01492887029288703|0.016718364543279556| 0.01877152620672991|\n",
      "|       Hybrid|0.010778242677824252|0.008833484494750564|0.009974498398269882|\n",
      "+-------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = [\n",
    "    (\"ALS\", als_metrics[\"Precision@10\"], als_metrics[\"Recall@10\"], als_metrics[\"NDCG@10\"]),\n",
    "    (\"Content-Based\", content_metrics[\"Precision@10\"], content_metrics[\"Recall@10\"], content_metrics[\"NDCG@10\"]),\n",
    "    (\"Hybrid\", hybrid_metrics[\"Precision@10\"], hybrid_metrics[\"Recall@10\"], hybrid_metrics[\"NDCG@10\"]),\n",
    "]\n",
    "spark.createDataFrame(summary, [\"Model\", \"Precision@10\", \"Recall@10\", \"NDCG@10\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample User ID: 2246\n",
      "\n",
      "=== Movies rated highly by this user (training data) ===\n",
      "+-------------------------------------------------------------------+--------------------+------+\n",
      "|title                                                              |genres              |rating|\n",
      "+-------------------------------------------------------------------+--------------------+------+\n",
      "|Shawshank Redemption, The (1994)                                   |Drama               |5.0   |\n",
      "|Henry V (1989)                                                     |Drama|War           |5.0   |\n",
      "|Three Colors: Red (1994)                                           |Drama               |5.0   |\n",
      "|Hud (1963)                                                         |Drama|Western       |5.0   |\n",
      "|Godfather: Part II, The (1974)                                     |Action|Crime|Drama  |5.0   |\n",
      "|Godfather, The (1972)                                              |Action|Crime|Drama  |5.0   |\n",
      "|Manhattan (1979)                                                   |Comedy|Drama|Romance|5.0   |\n",
      "|Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)|Action|Drama        |5.0   |\n",
      "|American Beauty (1999)                                             |Comedy|Drama        |5.0   |\n",
      "|Schindler's List (1993)                                            |Drama|War           |5.0   |\n",
      "+-------------------------------------------------------------------+--------------------+------+\n",
      "only showing top 10 rows\n",
      "=== Hybrid model recommendations ===\n",
      "+---------------------------------------------------------------------------+-------------------------+-------------------+\n",
      "|title                                                                      |genres                   |final_score        |\n",
      "+---------------------------------------------------------------------------+-------------------------+-------------------+\n",
      "|Time of the Gypsies (Dom za vesanje) (1989)                                |Drama                    |0.37719863985899266|\n",
      "|Mamma Roma (1962)                                                          |Drama                    |0.3767682087307902 |\n",
      "|Lamerica (1994)                                                            |Drama                    |0.3726963771291419 |\n",
      "|Specials, The (2000)                                                       |Comedy                   |0.3708421543204778 |\n",
      "|Inheritors, The (Die Siebtelbauern) (1998)                                 |Drama                    |0.3696586473542594 |\n",
      "|Sanjuro (1962)                                                             |Action|Adventure         |0.3618803264914765 |\n",
      "|Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)        |Action|Drama             |0.35277053280918425|\n",
      "|Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)|Sci-Fi|War               |0.35173927896838025|\n",
      "|Close Shave, A (1995)                                                      |Animation|Comedy|Thriller|0.3513345714729192 |\n",
      "|Usual Suspects, The (1995)                                                 |Crime|Thriller           |0.3509553127850636 |\n",
      "+---------------------------------------------------------------------------+-------------------------+-------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Sample User Recommendations Visualization\n",
    "import random\n",
    "\n",
    "# Pick a random user from test set\n",
    "test_users = test_df.select(\"user_id\").distinct().collect()\n",
    "sample_user_id = random.choice(test_users)[\"user_id\"]\n",
    "print(f\"Sample User ID: {sample_user_id}\\n\")\n",
    "\n",
    "# Get user's highly-rated movies from training set (rating >= 4)\n",
    "user_liked = train_df.filter(\n",
    "    (F.col(\"user_id\") == sample_user_id) & (F.col(\"rating\") >= 4.0)\n",
    ").join(items_df, \"item_id\").select(\"title\", \"genres\", \"rating\").orderBy(F.desc(\"rating\"))\n",
    "\n",
    "print(\"=== Movies rated highly by this user (training data) ===\")\n",
    "user_liked.show(10, truncate=False)\n",
    "\n",
    "# Get hybrid recommendations for this user\n",
    "user_recs = hybrid_recs.filter(F.col(\"user_id\") == sample_user_id) \\\n",
    "    .join(items_df, \"item_id\") \\\n",
    "    .select(\"title\", \"genres\", \"final_score\") \\\n",
    "    .orderBy(F.desc(\"final_score\"))\n",
    "\n",
    "print(\"=== Hybrid model recommendations ===\")\n",
    "user_recs.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import Evaluator\n",
    "from pyspark.ml import Estimator, Model\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "import time\n",
    "\n",
    "class ContentBasedEstimator(Estimator, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    numFeatures = Param(Params._dummy(), \"numFeatures\", \"num of tf-idf features\", TypeConverters.toInt)\n",
    "    bigramFeatures = Param(Params._dummy(), \"bigramFeatures\", \"num of bigram features\", TypeConverters.toInt)\n",
    "    numHashTables = Param(Params._dummy(), \"numHashTables\", \"num of LSH hash tables\", TypeConverters.toInt)\n",
    "    jaccardThreshold = Param(Params._dummy(), \"jaccardThreshold\", \"jaccard similarity threshold\", TypeConverters.toFloat)\n",
    "    minGenreOverlap = Param(Params._dummy(), \"minGenreOverlap\", \"minimum genre overlap\", TypeConverters.toInt)\n",
    "    \n",
    "    def __init__(self, numFeatures=5000, bigramFeatures=3000, \n",
    "                numHashTables=10, jaccardThreshold=0.1, minGenreOverlap=1):\n",
    "        super(ContentBasedEstimator, self).__init__()\n",
    "        self._setDefault(numFeatures=numFeatures, \n",
    "                        bigramFeatures=bigramFeatures, \n",
    "                        numHashTables=numHashTables,\n",
    "                        jaccardThreshold=jaccardThreshold,\n",
    "                        minGenreOverlap=minGenreOverlap)\n",
    "        \n",
    "        self._set(numFeatures=numFeatures, \n",
    "                bigramFeatures=bigramFeatures, \n",
    "                numHashTables=numHashTables,\n",
    "                jaccardThreshold=jaccardThreshold, \n",
    "                minGenreOverlap=minGenreOverlap)\n",
    "    \n",
    "    def _fit(self, dataset):\n",
    "        cb = ContentBasedFilter(\n",
    "            num_features=self.getOrDefault(self.numFeatures),\n",
    "            bigram_features=self.getOrDefault(self.bigramFeatures),\n",
    "            num_hash_tables=self.getOrDefault(self.numHashTables)\n",
    "        )\n",
    "        cb.jaccard_threshold = self.getOrDefault(self.jaccardThreshold)\n",
    "        cb.min_genre_overlap = self.getOrDefault(self.minGenreOverlap)\n",
    "        cb.train_features(items_df)\n",
    "        cb.build_lsh_index()\n",
    "        return ContentBasedModel(cb)\n",
    "\n",
    "class ContentBasedModel(Model, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def __init__(self, cb_filter=None):\n",
    "        super(ContentBasedModel, self).__init__()\n",
    "        self.cb_filter = cb_filter\n",
    "    \n",
    "    def _transform(self, dataset):\n",
    "        if self.cb_filter is None:\n",
    "            raise ValueError(\"model not fitted\")\n",
    "        return self.cb_filter.recommend_for_users(dataset, items_df, k=100)\n",
    "\n",
    "class RecSysEvaluator(Evaluator):\n",
    "    def __init__(self, test_df, ground_truth, k=10):\n",
    "        super(RecSysEvaluator, self).__init__()\n",
    "        self.test_df = test_df\n",
    "        self.ground_truth = ground_truth\n",
    "        self.k = k\n",
    "    \n",
    "    def _evaluate(self, dataset):\n",
    "        top_k = get_top_k(dataset, \"content_score\", self.k)\n",
    "        return ndcg_at_k(top_k, self.ground_truth, self.k)\n",
    "    \n",
    "    def isLargerBetter(self):\n",
    "        return True\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(ContentBasedEstimator.numFeatures, [3000, 5000, 7000]) \\\n",
    "    .addGrid(ContentBasedEstimator.bigramFeatures, [2000, 3000]) \\\n",
    "    .addGrid(ContentBasedEstimator.numHashTables, [10, 20, 30]) \\\n",
    "    .addGrid(ContentBasedEstimator.jaccardThreshold, [0.1, 0.2]) \\\n",
    "    .addGrid(ContentBasedEstimator.minGenreOverlap, [1, 2]) \\\n",
    "    .build()\n",
    "\n",
    "estimator = ContentBasedEstimator()\n",
    "evaluator = RecSysEvaluator(test_df, ground_truth, k=10)\n",
    "items_df.cache()\n",
    "train_df.cache()\n",
    "cv = CrossValidator(estimator=estimator, estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, numFolds=2, parallelism=10)\n",
    "\n",
    "start = time.time()\n",
    "cvModel = cv.fit(train_df)\n",
    "train_time = time.time() - start\n",
    "\n",
    "best_model = cvModel.bestModel\n",
    "print(f\"Training time: {train_time:.2f}s\")\n",
    "print(f\"Best params: numFeatures={best_model.cb_filter.num_features}, bigramFeatures={best_model.cb_filter.bigram_features}, numHashTables={best_model.cb_filter.num_hash_tables}, jaccardThreshold={best_model.cb_filter.jaccard_threshold:.3f}, minGenreOverlap={best_model.cb_filter.min_genre_overlap}\")\n",
    "\n",
    "start = time.time()\n",
    "tuned_recs = best_model.transform(train_df).cache()\n",
    "inference_time = time.time() - start\n",
    "\n",
    "tuned_metrics = evaluate(tuned_recs, \"content_score\", \"Tuned Content-Based\")\n",
    "print(f\"Inference time: {inference_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "26/01/17 19:33:09 WARN CacheManager: Asked to cache already cached data.\n",
    "26/01/17 19:33:09 WARN CacheManager: Asked to cache already cached data.\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairsindexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "building content features (tfidf + bigrams)\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "building content features (tfidf + bigrams)\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "checked 3883 moviesgenerating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "\n",
    "indexing with minhash LSH\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "building content features (tfidf + bigrams)\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendationsgenerating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "\n",
    "generating content-based recommendations\n",
    "indexing with minhash LSH\n",
    "generating content-based recommendations\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "building content features (tfidf + bigrams)\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "indexed 988212 similar item pairsindexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "building content features (tfidf + bigrams)\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 moviesindexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "checked 3883 movies\n",
    "indexed 988212 similar item pairs\n",
    "\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "indexing with minhash LSH\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graphcmputing similarity graph\n",
    "\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "indexed 988212 similar item pairsindexed 988212 similar item pairs\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "generating content-based recommendations\n",
    "\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "...\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
    "                                                                                \n",
    "indexed 988212 similar item pairsindexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "building content features (tfidf + bigrams)\n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "cmputing similarity graph\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "indexed 988212 similar item pairsindexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "...\n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movieschecked 3883 movies\n",
    "indexing with minhash LSH\n",
    "\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graphcmputing similarity graph\n",
    "\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "indexed 988212 similar item pairsindexed 988212 similar item pairs\n",
    "\n",
    "indexed 988212 similar item pairs\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "cmputing similarity graph\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "                                                                                \n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "building content features (tfidf + bigrams)\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "checked 3883 movieschecked 3883 movies\n",
    "indexing with minhash LSH\n",
    "\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "building content features (tfidf + bigrams)\n",
    "                                                                                \n",
    "checked 3883 movies\n",
    "indexing with minhash LSH\n",
    "cmputing similarity graph\n",
    "                                                                                \n",
    "indexed 988212 similar item pairs\n",
    "Training time: 5721.41s\n",
    "Best params: numFeatures=5000, bigramFeatures=3000, numHashTables=10, jaccardThreshold=0.100, minGenreOverlap=1\n",
    "generating content-based recommendations\n",
    "                                                                                \n",
    "Tuned Content-Based: P@10=0.0150, R@10=0.0167, NDCG@10=0.0188\n",
    "Inference time: 0.09s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mining-massive-databases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
